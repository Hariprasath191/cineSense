{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KngbS0cSfC01"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = r'/content/drive/MyDrive/dataset/IMDB Dataset.csv'"
      ],
      "metadata": {
        "id": "18R8yzQtfpPL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj4NhiHxfrdq",
        "outputId": "06fe76fa-0aa9-4d8d-b7ff-fefa5fe7adeb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())  # Check for missing values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x59lymq9fuxT",
        "outputId": "8e0a9a54-9908-4816-ce15-2f7c752cfff4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review       0\n",
            "sentiment    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns:\", df.columns)\n",
        "print(df.describe())  # Summary statistics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4-4xkBkfwOX",
        "outputId": "501920e1-520d-42bb-b6c6-4f85f94c13e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: Index(['review', 'sentiment'], dtype='object')\n",
            "                                                   review sentiment\n",
            "count                                               50000     50000\n",
            "unique                                              49582         2\n",
            "top     Loved today's show!!! It was a variety and not...  positive\n",
            "freq                                                    5     25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Removing HTML tags\n",
        "\n",
        "✅ Converting text to lowercase\n",
        "\n",
        "✅ Removing special characters & punctuation\n",
        "\n",
        "✅ Removing stopwords\n",
        "\n",
        "✅ Tokenization & Lemmatization"
      ],
      "metadata": {
        "id": "aTgyTDGqf1cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re  # Regular expressions for text cleaning\n",
        "import nltk  # Natural Language Toolkit for text processing\n",
        "from bs4 import BeautifulSoup  # HTML tag removal\n",
        "from nltk.corpus import stopwords  # List of common words like 'the', 'is', etc.\n",
        "from nltk.tokenize import word_tokenize  # Splits text into words\n",
        "from nltk.stem import WordNetLemmatizer  # Reduces words to their root form\n"
      ],
      "metadata": {
        "id": "fKYqEMmsfwLA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")  # Stopwords list\n",
        "nltk.download(\"punkt\")  # Tokenizer\n",
        "nltk.download(\"wordnet\")  # Lemmatizer dictionary\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCnYzLlxfwIY",
        "outputId": "71c91dc4-905c-490a-b81c-fc6a24af010b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()  # Converts words to base form (e.g., \"running\" → \"run\")\n",
        "stop_words = set(stopwords.words(\"english\"))  # Load a list of common stopwords\n"
      ],
      "metadata": {
        "id": "Qn3fH3nSfwF3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    #text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters\n",
        "    tokens = word_tokenize(text)  # Tokenization: Split text into words\n",
        "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization\n",
        "    return \" \".join(tokens)  # Join words back into cleaned text\n"
      ],
      "metadata": {
        "id": "UIKZrVs3fwDX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"clean_review\"] = df[\"review\"].apply(preprocess_text)  # Apply function to all reviews\n",
        "print(df.head())  # Check cleaned data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4gLuZtifwAt",
        "outputId": "95784e95-743c-4639-c395-cf0faade8ff8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment  \\\n",
            "0  One of the other reviewers has mentioned that ...  positive   \n",
            "1  A wonderful little production. <br /><br />The...  positive   \n",
            "2  I thought this was a wonderful way to spend ti...  positive   \n",
            "3  Basically there's a family where a little boy ...  negative   \n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
            "\n",
            "                                        clean_review  \n",
            "0  one reviewer mentioned watching oz episode you...  \n",
            "1  wonderful little production br br filming tech...  \n",
            "2  thought wonderful way spend time hot summer we...  \n",
            "3  basically there family little boy jake think t...  \n",
            "4  petter matteis love time money visually stunni...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction"
      ],
      "metadata": {
        "id": "98FnY32DgNPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting to 5000 important words\n",
        "\n",
        "# Convert text data into TF-IDF vectors\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df[\"clean_review\"])\n",
        "\n",
        "# Extract labels (target variable)\n",
        "y = df[\"sentiment\"]  # Assuming 'sentiment' is the column with labels (positive/negative)\n",
        "\n",
        "# Save the vectorizer\n",
        "joblib.dump(tfidf_vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "\n",
        "print(\"Vectorizer saved as tfidf_vectorizer.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EANTDgHUfv97",
        "outputId": "4ca7b2e8-4ffa-4c8a-b33e-58c69f144374"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorizer saved as tfidf_vectorizer.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Machine Learning Model"
      ],
      "metadata": {
        "id": "K5IsijOmgP6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Split dataset into training & testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL_gbLP-fvvT",
        "outputId": "ca8b5a09-b414-4d20-f89e-5de434f219b2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8846\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.87      0.88      4961\n",
            "    positive       0.88      0.90      0.89      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test on New Reviews"
      ],
      "metadata": {
        "id": "qSqpt0PxgWFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "41RG8Tu-h2ux"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "joblib.dump(model, \"sentiment_model.pkl\")\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiZtlKdCmYtJ",
        "outputId": "58a8c610-2ffd-4bad-a300-17ac6a01dbe8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_reviews = [\"This movie was fantastic and full of emotions!\", \"It was the worst film I have ever seen.\"]\n",
        "new_reviews_tfidf = tfidf_vectorizer.transform(new_reviews)\n",
        "\n",
        "# Predict sentiment\n",
        "predictions = model.predict(new_reviews_tfidf)\n",
        "\n",
        "print(predictions)  # Output: ['positive', 'negative']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAcKz4IXgWii",
        "outputId": "15a7f272-0f63-49a5-d33d-196db85c1497"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive' 'negative']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try Naïve Bayes (MultinomialNB)"
      ],
      "metadata": {
        "id": "OGjY1gC2ga5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Train Naïve Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeMD28z3gbYE",
        "outputId": "3f8fc302-77bc-4b3b-a760-6d9529d310ca"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naïve Bayes Accuracy: 0.8519\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.85      0.85      4961\n",
            "    positive       0.85      0.86      0.85      5039\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try Random Forest"
      ],
      "metadata": {
        "id": "z3QOr9_Ngfzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mBaH1ggggOX",
        "outputId": "a25adfd8-326f-4766-bf85-071b26e9c351"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.8506\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.86      0.85      4961\n",
            "    positive       0.86      0.85      0.85      5039\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try SVM"
      ],
      "metadata": {
        "id": "pjCgJgyMgiGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "id": "Xcidw3KigkqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "joblib.dump(svm_model, \"sentiment_model_svm.pkl\")\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "HZmhN5Q0rwIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tune Hyperparameters for Better Performance"
      ],
      "metadata": {
        "id": "ce0iQde7goVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],  # Regularization strength\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Train model with best params\n",
        "best_lr = grid_search.best_estimator_\n",
        "y_pred_best = best_lr.predict(X_test)\n",
        "print(\"Tuned Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_best))\n"
      ],
      "metadata": {
        "id": "ESjPn_C5gozU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1d1LbZFXlTzH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}