{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e526afb3-42ad-45b5-b5c4-f4ac099ebf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4879b2-e0ad-4cea-8b3e-3c44de77dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1efb27-5187-4a77-b732-6b7b7d93914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\My drive\\Studies\\sem_6\\NLP\\Project\\Datasets\\IBM\\IMDB Dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10a4756-d8fe-477f-97dd-ac9710ab2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3ac4ac-09a6-49ca-8440-97162c1ec12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())  # Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7a38b1-a98f-486f-b651-648d4b618a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['review', 'sentiment'], dtype='object')\n",
      "                                                   review sentiment\n",
      "count                                               50000     50000\n",
      "unique                                              49582         2\n",
      "top     Loved today's show!!! It was a variety and not...  positive\n",
      "freq                                                    5     25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", df.columns)\n",
    "print(df.describe())  # Summary statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320ee83-c24a-4e67-8537-99d1849ac08b",
   "metadata": {},
   "source": [
    "✅ Removing HTML tags\n",
    "\n",
    "✅ Converting text to lowercase\n",
    "\n",
    "✅ Removing special characters & punctuation\n",
    "\n",
    "✅ Removing stopwords\n",
    "\n",
    "✅ Tokenization & Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e3712-5f1f-4b63-b006-8c106313f548",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3cff55-eda1-47c7-a260-3e6f8344a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # Regular expressions for text cleaning\n",
    "import nltk  # Natural Language Toolkit for text processing\n",
    "from bs4 import BeautifulSoup  # HTML tag removal\n",
    "from nltk.corpus import stopwords  # List of common words like 'the', 'is', etc.\n",
    "from nltk.tokenize import word_tokenize  # Splits text into words\n",
    "from nltk.stem import WordNetLemmatizer  # Reduces words to their root form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4095fbde-aa39-4a75-9810-1a824bde0c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")  # Stopwords list\n",
    "nltk.download(\"punkt\")  # Tokenizer\n",
    "nltk.download(\"wordnet\")  # Lemmatizer dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae43c4b-37c0-47e3-a208-625a276866fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\shari\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc261588-955a-4363-9f29-41cd1946dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()  # Converts words to base form (e.g., \"running\" → \"run\")\n",
    "stop_words = set(stopwords.words(\"english\"))  # Load a list of common stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d2f33c0-37a7-4683-9dd7-98479f00cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    #text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters\n",
    "    tokens = word_tokenize(text)  # Tokenization: Split text into words\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization\n",
    "    return \" \".join(tokens)  # Join words back into cleaned text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "389ee7c5-ea96-4069-ac32-309e0d0257b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment  \\\n",
      "0  One of the other reviewers has mentioned that ...  positive   \n",
      "1  A wonderful little production. <br /><br />The...  positive   \n",
      "2  I thought this was a wonderful way to spend ti...  positive   \n",
      "3  Basically there's a family where a little boy ...  negative   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
      "\n",
      "                                        clean_review  \n",
      "0  one reviewer mentioned watching oz episode you...  \n",
      "1  wonderful little production br br filming tech...  \n",
      "2  thought wonderful way spend time hot summer we...  \n",
      "3  basically there family little boy jake think t...  \n",
      "4  petter matteis love time money visually stunni...  \n"
     ]
    }
   ],
   "source": [
    "df[\"clean_review\"] = df[\"review\"].apply(preprocess_text)  # Apply function to all reviews\n",
    "print(df.head())  # Check cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e4ed21-1960-43eb-b638-f4891f57eb15",
   "metadata": {},
   "source": [
    "Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8547bce0-42a0-467e-b45a-21e17ab975db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limiting to 5000 important words\n",
    "\n",
    "# Convert text data into TF-IDF vectors\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df[\"clean_review\"])\n",
    "\n",
    "# Extract labels (target variable)\n",
    "y = df[\"sentiment\"]  # Assuming 'sentiment' is the column with labels (positive/negative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2766e-8d0e-4b5a-a789-61c147ff7d6b",
   "metadata": {},
   "source": [
    "Train a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2ae44f-a7f2-4e4e-bdab-d017c676c933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8846\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88      4961\n",
      "    positive       0.88      0.90      0.89      5039\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split dataset into training & testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b160ac-f0c7-445e-a1a7-5b4229d0cd7d",
   "metadata": {},
   "source": [
    "Test on New Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e0b24bb-b758-48c5-92ec-731fcb9c72d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "new_reviews = [\"This movie was fantastic and full of emotions!\", \"It was the worst film I have ever seen.\"]\n",
    "new_reviews_tfidf = tfidf_vectorizer.transform(new_reviews)\n",
    "\n",
    "# Predict sentiment\n",
    "predictions = model.predict(new_reviews_tfidf)\n",
    "\n",
    "print(predictions)  # Output: ['positive', 'negative']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9465a48-5301-4731-8434-15971a70ffa9",
   "metadata": {},
   "source": [
    "trying different models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fede6c-5c6a-4f6a-bef4-b346f62fbe7b",
   "metadata": {},
   "source": [
    "Try Naïve Bayes (MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ee90f78-8fa0-40bd-b3ce-f1da9a2848fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.8518\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85      4961\n",
      "    positive       0.85      0.86      0.85      5039\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train Naïve Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a1956-2c6a-495f-96b0-c08af75af749",
   "metadata": {},
   "source": [
    "Try Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "396c728a-5ff0-49d5-97f9-ab2a4d7f84b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8531\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85      4961\n",
      "    positive       0.86      0.85      0.85      5039\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f88522-d008-40fc-9fb2-22a1108a86ea",
   "metadata": {},
   "source": [
    "Try SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86da977-c2ec-40eb-9f10-dc0b4bffc6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8863\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88      4961\n",
      "    positive       0.88      0.90      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d694aa-cb3e-495e-a485-2caa43b1ac5f",
   "metadata": {},
   "source": [
    " Tune Hyperparameters for Better Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9e1cc7d-9146-4562-ac4a-78a4975afe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'solver': 'lbfgs'}\n",
      "Tuned Logistic Regression Accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train model with best params\n",
    "best_lr = grid_search.best_estimator_\n",
    "y_pred_best = best_lr.predict(X_test)\n",
    "print(\"Tuned Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ce25538-ac7f-4096-8a6b-8ae456403e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c8b18d2-7d4f-4d84-b811-ee62f9640124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "joblib.dump(svm_model, \"sentiment_model_svm.pkl\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8f50b62-cc63-4c83-afff-928b808aadd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\My drive\\\\Studies\\\\sem_6\\\\NLP\\\\Project\\\\Code'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234958ae-2425-40e2-8b89-77267c567fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495e387-649e-4c37-99f3-6400861a53c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
